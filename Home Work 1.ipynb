{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60683504",
   "metadata": {},
   "source": [
    "## Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269bbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798c2b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = titanic_data.isnull().sum()\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eab006",
   "metadata": {},
   "source": [
    "## Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9f1536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 891\n",
      "Number of columns: 12\n"
     ]
    }
   ],
   "source": [
    "rows, columns = titanic_data.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918b71a",
   "metadata": {},
   "source": [
    "### My own general definitions of the meaning of \"obervations\" and \"variables\":\n",
    "\n",
    "#### 1. Oberservations: It refers to some data we will focus on analyzing that contains a bunch of more detailed information.\n",
    "\n",
    "#### 2. Variables: It refers to data with detailed information, such as the features and characteristics that make up an observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f8810",
   "metadata": {},
   "source": [
    "## Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a3cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "summary = titanic_data.describe()\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3991530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "Embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "Pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic_data['Sex'].value_counts())\n",
    "print(titanic_data['Embarked'].value_counts())\n",
    "print(titanic_data['Pclass'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c37174e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_per_column = titanic_data.isnull().sum()\n",
    "print(missing_values_per_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "421c6b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0.0\n",
      "Survived         0.0\n",
      "Pclass           0.0\n",
      "Age            177.0\n",
      "SibSp            0.0\n",
      "Parch            0.0\n",
      "Fare             0.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of rows\n",
    "total_rows = titanic_data.shape[0]\n",
    "\n",
    "# Get the count of non-missing values for each column from describe\n",
    "counts_from_describe = titanic_data.describe().loc['count']\n",
    "\n",
    "# Compare and print discrepancies\n",
    "discrepancies = total_rows - counts_from_describe\n",
    "print(discrepancies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c50be817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with at least one missing value: 708\n"
     ]
    }
   ],
   "source": [
    "rows_with_missing = titanic_data.isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with at least one missing value: {rows_with_missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6220ef2",
   "metadata": {},
   "source": [
    "## Step 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020c05e7",
   "metadata": {},
   "source": [
    "### The discrepancies between the size of the dataset given by df.shape and what is reported by df.describe() occur because df.shape will count all the observations in the dataset no matter if there is a missing value or not, and df.describe() only count the observations that have no missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba1edd",
   "metadata": {},
   "source": [
    "## Step 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533d1a3",
   "metadata": {},
   "source": [
    "### The difference between \"attribute\" and \"method\" is that \"attribute\" refers to a certain character of data which cannot be changed or edited, and \"method\" refers to a function that we can use to make changes to some data and take some actions like computing to acquire some consequences we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bce998",
   "metadata": {},
   "source": [
    "## Step 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf074c",
   "metadata": {},
   "source": [
    "### df.describe( ):\n",
    "\n",
    "    1. count: The number of non-missing data for each numerical column.\n",
    "    2. mean: The average value of each numerical column.\n",
    "    3. sta: The standard deviation of each numerical column.\n",
    "    4. min: The minimum value found in each numerical column.\n",
    "    5. 25%: The 25th percentile in each numerical column.\n",
    "    6. 50%: The 50th percentile in each numerical column.\n",
    "    7. 75%: The 75th percentile in each numerical column.\n",
    "    8. max: The maximum value found in each numerical column.\n",
    "\n",
    "    df.describe() will ignore missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700be18",
   "metadata": {},
   "source": [
    "## Step 7\n",
    "\n",
    "### Q1: When I distribute a survey online and make a dataset out of the data I get, it has columns for name, date of birth, hobbies, and hours of sleep, but not all the respondents answered all the questions, resulting in some of the rows in my dataset missing some of the data, and I only want to analyze the data that is complete, then I can use df.dropna() instead of del df['col'].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f6c75",
   "metadata": {},
   "source": [
    "### Q2: When I analyzed the dataset I collected from a survey online, I noticed that almost no one answered the \"sleep hours\" question. Since this column has little valuable information, I decided to delete the whole columnthen, then I can use del df['col'] instead of df.dropna().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97b7d0",
   "metadata": {},
   "source": [
    "### Q3: Since there may be some columns with much missing data and little value to analyze, our main goal is to delete the columns. If we use df.dropna() first, it will delete all rows with missing data, which will cause unnecessary data loss. So it is important to apply del df['col'] before df.dropna() when both are used together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d380c31",
   "metadata": {},
   "source": [
    "### Q4: When removing all missing data, I will first use del df['col'] to delete all columns that have little valuable information, then I will use df.dropna() to delete the rest rows with missing data. Before applying the approach, the dataset will have multiple columns and rows with missing data, and after applying the approach, all the columns with missing data and the rest of the rows with missing data will be deleted, which means that there will be no missing data after applying the approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c0874",
   "metadata": {},
   "source": [
    "## Step 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c92869",
   "metadata": {},
   "source": [
    "### Q1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a22bf22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url1 = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url1)\n",
    "\n",
    "print (df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7766eebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count       mean        std   min   25%   50%   75%   max\n",
      "survived                                                           \n",
      "0         424.0  30.626179  14.172110  1.00  21.0  28.0  39.0  74.0\n",
      "1         290.0  28.343690  14.950952  0.42  19.0  28.0  36.0  80.0\n"
     ]
    }
   ],
   "source": [
    "grouped_description = df.groupby(\"survived\")[\"age\"].describe()\n",
    "\n",
    "print(grouped_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4619e1",
   "metadata": {},
   "source": [
    "### Q2: The difference exists because df.describe() counts all the non-missing values of the whole column, and something like df.groupby(\"col1\")[\"col2\"].describe() counts non-missing values from each divided group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc03ea",
   "metadata": {},
   "source": [
    "### Q3: It is easier to work in a ChatBot session to fix the errors. We can use ChatBot to fix the coding errors. Google provided me with a lot of websites which were not as easy as ChatBot to find solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3017a",
   "metadata": {},
   "source": [
    "## Step 9:\n",
    "### Somewhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb522f32",
   "metadata": {},
   "source": [
    "## ChatBot Links and Summaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f3836",
   "metadata": {},
   "source": [
    "### 1. First dataset used from TUT: https://chatgpt.com/share/aa9bb2c8-5713-42c2-a02f-c7669c479a0f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961c496",
   "metadata": {},
   "source": [
    "### 2. Link:https://chatgpt.com/c/66e0ec5b-7b60-8003-94d1-3376120fe376"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf128c",
   "metadata": {},
   "source": [
    "### Summary: Here's a summary of our conversation:\n",
    "\n",
    "Missing Values in the Dataset:\n",
    "\n",
    "You learned how to identify missing values in a dataset using df.isnull().sum(), which shows the number of missing values in each column.\n",
    "Dataset Dimensions:\n",
    "\n",
    "You discovered how to check the number of rows and columns in the dataset using df.shape, which returns a tuple with the count of rows and columns.\n",
    "Observations vs. Variables:\n",
    "\n",
    "Observations: The individual data points or records in the dataset (each row represents a passenger in the Titanic dataset).\n",
    "Variables: The attributes or features of the observations (each column represents a different attribute, such as Age, Sex, etc.).\n",
    "Summarizing the Dataset:\n",
    "\n",
    "The simplest summary of the dataset can be achieved using df.describe(), which provides key statistical measures (like count, mean, std, min, max, and percentiles) for numerical columns.\n",
    "Additional methods for summarization include df.info() (for data types and missing values), df.head() (for viewing the first few rows), value_counts() (for categorical columns), and correlation analysis.\n",
    "Attributes vs. Methods:\n",
    "\n",
    "Attributes (e.g., df.shape) provide stored information about an object and do not require parentheses.\n",
    "Methods (e.g., df.describe()) perform actions or calculations on the data and require parentheses to execute.\n",
    "What df.describe() Provides:\n",
    "\n",
    "df.describe() gives a statistical summary of numerical columns by default, showing count, mean, standard deviation, min, max, and percentiles. It can also be customized to include all columns (numerical and categorical).\n",
    "Handling Missing Data in df.describe():\n",
    "\n",
    "Missing data is automatically excluded from calculations in df.describe(). The count reflects the number of non-missing values, while other statistics are calculated based only on non-missing data.\n",
    "Checking for Discrepancies:\n",
    "\n",
    "To check for discrepancies between the size of the dataset (from df.shape) and the summary provided by df.describe(), you can compare the counts and look for missing data in columns.\n",
    "This summary captures the key points from our discussion about analyzing and summarizing data using pandas in Python, focusing on understanding attributes, methods, and handling missing data in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4d94b",
   "metadata": {},
   "source": [
    "### 3. Link:https://chatgpt.com/c/66e211f3-9e58-8003-a608-1f271984d25b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a3f31",
   "metadata": {},
   "source": [
    "### Summary: Here's a summary of our conversation:\n",
    "\n",
    "Use Cases for df.dropna() vs. del df['col']:\n",
    "\n",
    "df.dropna() is preferred when you want to remove rows or columns with missing values. This is useful for data cleaning, where you need to keep only complete records.\n",
    "del df['col'] is preferred when you want to remove an entire column that is irrelevant or not needed for your analysis, regardless of whether it has missing values.\n",
    "Importance of Using del df['col'] Before df.dropna():\n",
    "\n",
    "Applying del df['col'] before df.dropna() prevents the unintended removal of rows due to missing values in columns you plan to delete anyway. It avoids unnecessary data loss and improves efficiency by focusing only on the columns that are relevant to your analysis.\n",
    "Removing All Missing Data from a Dataset:\n",
    "\n",
    "You can combine del df['col'] and df.dropna() to remove all missing data:\n",
    "First, use del df['col'] to remove irrelevant columns.\n",
    "Then, apply df.dropna() to remove rows or columns that contain any remaining missing values.\n",
    "This approach ensures that only necessary data is kept and all missing values are removed effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b3cfbc",
   "metadata": {},
   "source": [
    "### 4. Link: https://chatgpt.com/c/66e220b8-3214-8003-b4ba-27524370d842"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123a720",
   "metadata": {},
   "source": [
    "### Summary: Here's a summary of our conversation:\n",
    "\n",
    "Initial Request: You wanted to perform some initial summary analyses on the Titanic dataset and needed help understanding specific parts of your code.\n",
    "\n",
    "Understanding groupby().describe():\n",
    "\n",
    "We discussed what the df.groupby(\"col1\")[\"col2\"].describe() code does. It groups the DataFrame by the unique values in col1 and computes descriptive statistics (like count, mean, std, min, max, etc.) for col2 within each group.\n",
    "Count Differences Explanation:\n",
    "\n",
    "I explained why the count values might differ between df.describe() and df.groupby(\"col1\")[\"col2\"].describe(). The former computes statistics for the entire column, while the latter calculates statistics for each group separately.\n",
    "Common Errors and Fixes:\n",
    "\n",
    "NameError: name 'pd' is not defined: This error was due to the pandas library not being imported. The solution was to include import pandas as pd at the beginning of your code.\n",
    "HTTPError: HTTP Error 404: Not Found: The URL used to load the Titanic dataset was incorrect, and I provided the correct URL.\n",
    "FileNotFoundError: Explained that this error could occur due to network issues or a typo in the file path or URL.\n",
    "NameError: name 'DF' is not defined: This error happened because Python is case-sensitive, and df should be lowercase.\n",
    "SyntaxError: '(' was never closed: Explained that this error is due to a missing closing parenthesis and provided guidance on ensuring all parentheses are balanced.\n",
    "AttributeError: 'DataFrame' object has no attribute 'group_by': This was caused by using the incorrect method name group_by instead of groupby.\n",
    "KeyError: 'Column not found: Age': The error occurred due to using an incorrect column name (Age instead of age). We discussed how to check the DataFrame’s columns using df.columns.\n",
    "NameError: name 'age' is not defined: This error was due to not using quotes around the column name age. I clarified the need to enclose column names in quotes.\n",
    "Final Guidance: I provided detailed explanations and corrected code snippets for each of these errors to help you resolve them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8fbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
