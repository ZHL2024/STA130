{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3775c0",
   "metadata": {},
   "source": [
    "## Q1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74cd870",
   "metadata": {},
   "source": [
    "#### The key factor that makes the difference between ideas that can, and cannot be examined and tested statistically is that whether we have data which can be examined to verify the idea.\n",
    "#### I think the key criteria defining a good null hypothesis is that it should be able to test by data, and it shouldn't be too far from the actual value we get.\n",
    "#### The difference between a null hypothesis and an alternative hypothesis is that the null hypothesis wants to show the case is true, while the alternative hypothesis wants to show the null hypothesis is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d289cc56",
   "metadata": {},
   "source": [
    "## Q2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb2c13",
   "metadata": {},
   "source": [
    "#### xi: It refers to the i^th data of the sample which is called X.\n",
    "#### x bar: It refers to the mean of the sample.\n",
    "#### mu: It refers to the population mean which is estimated by the mean of samples.\n",
    "#### mu0: It refers to the population mean which is assumed in the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efded53",
   "metadata": {},
   "source": [
    "## Q3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff1b477",
   "metadata": {},
   "source": [
    "#### Since p-value evaluates the probability of getting observed sequence when assuming the null hypothesis is true. Thus the precondition we must set is that we assume the null hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db91f0",
   "metadata": {},
   "source": [
    "## Q4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39866baa",
   "metadata": {},
   "source": [
    "\n",
    "#### When the p-value is samll, the sample where the test statistics we observed are in it is almost impossible to see in the population in the basis of the null hypothesis is true. However, the sample is randomly chosen, which means that it should not be so rare to find. Thus, it is more likely that the null hypothesis itself is ridiculous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae4743",
   "metadata": {},
   "source": [
    "## Q5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5f2d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "H0 = 0.5\n",
    "observed_statistic = 0.645\n",
    "\n",
    "np.random.seed(1)\n",
    "n = 10000\n",
    "n_size = 124\n",
    "simulation_underH0 = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    random_improvement = np.random.choice([0,1],size = n_size, replace = True)\n",
    "    simulation_underH0[i] = random_improvement.mean()\n",
    "\n",
    "simulated_statistics = simulation_underH0\n",
    "extreme_than_observed = abs(simulated_statistics - H0) >= abs(observed_statistic - H0)\n",
    "extreme_than_observed.sum()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814617b",
   "metadata": {},
   "source": [
    "Since p-value = 0.0015, we have strong evidence against the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67ba32",
   "metadata": {},
   "source": [
    "## Q6:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af1727",
   "metadata": {},
   "source": [
    "#### A small p-value cannot prove that the null hypothesis is false. It can only indicate that when we assume that the null hypothesis is true, the sample is very hard to be observed, which means that we may be more likely to believe that the null hypothesis is false but cannot ensure that the null hypothesis is false.\n",
    "#### We cannot use p-value to prove that Fido is either innocent or guilty, no matter how high or low the p-value is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae877a86",
   "metadata": {},
   "source": [
    "## Q7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9411b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Simulations: 10000\n",
      "\n",
      "Number of simulated statistics (under H0)\n",
      "that are \"as or more extreme\" than the observed statistic: 565\n",
      "\n",
      "p-value\n",
      "(= simulations \"as or more extreme\" / total simulations): 0.0565\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "patient_data = pd.DataFrame({\n",
    "    \"PatientID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"Age\": [45, 34, 29, 52, 37, 41, 33, 48, 26, 39],\n",
    "    \"Gender\": [\"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n",
    "    \"InitialHealthScore\": [84, 78, 83, 81, 81, 80, 79, 85, 76, 83],\n",
    "    \"FinalHealthScore\": [86, 86, 80, 86, 84, 86, 86, 82, 83, 84]\n",
    "})\n",
    "\n",
    "patient_data['HealthScoreChange'] = patient_data.FinalHealthScore-patient_data.InitialHealthScore\n",
    "\n",
    "np.random.seed(1)\n",
    "number_of_simulations = 10000\n",
    "n_size = len(patient_data)\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "for i in range(number_of_simulations):\n",
    "    random_improvement = np.random.choice([0,1], size=len(patient_data), replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "# Assuming H0 is that the improvement is random (50% chance)\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "# Observed proportion of patients who improved\n",
    "observed_statistic = (patient_data.HealthScoreChange > 0).mean()\n",
    "\n",
    "# Simulated statistics\n",
    "simulated_statistics = IncreaseProportionSimulations_underH0random\n",
    "\n",
    "# One-sided test: Simulations \"as or more extreme\" for a greater-than test\n",
    "SimStats_as_or_more_extreme_than_ObsStat = \\\n",
    "    simulated_statistics >= observed_statistic\n",
    "\n",
    "# p-value calculation (one-sided)\n",
    "p_value_one_sided = SimStats_as_or_more_extreme_than_ObsStat.sum() / number_of_simulations\n",
    "\n",
    "# Output the results\n",
    "print(\"Number of Simulations: \", number_of_simulations, \"\\n\\n\",\n",
    "      \"Number of simulated statistics (under H0)\\n\",\n",
    "      'that are \"as or more extreme\" than the observed statistic: ',\n",
    "      SimStats_as_or_more_extreme_than_ObsStat.sum(), \"\\n\\n\",\n",
    "      'p-value\\n(= simulations \"as or more extreme\" / total simulations): ', p_value_one_sided, sep=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9383499b",
   "metadata": {},
   "source": [
    "The one-sided test is more specific, and typically has more power to detect an effect in the direction you're testing (in this case, improvement). However, it won't capture any cases where the observed statistic might be significantly lower than expected. By changing to a one-sided test, you're focusing only on the hypothesis that the patients' improvement is greater than what would be expected by chance, rather than testing for any difference (greater or less)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0e792d",
   "metadata": {},
   "source": [
    "In practice, if the observed statistic falls in the direction of your one-tailed hypothesis, the p-value will generally be smaller for the one-tailed test because you're only focusing on one side of the distribution. However, if the observed statistic does not fall in the direction of your one-tailed hypothesis, the p-value may not necessarily be smaller (and could be larger).\n",
    "\n",
    "Therefore, the p-value in a one-tailed test will usually be smaller than in a two-tailed test, as long as the result is in the direction you're testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6905436",
   "metadata": {},
   "source": [
    "#### Summary: Code Overview:\n",
    "\n",
    "You provided a simulation-based hypothesis test to assess whether there is significant improvement in patient health scores, using a two-tailed (two-sided) test. The code ran 10,000 simulations to compare the observed proportion of patients with health score improvements to random chance (null hypothesis), and calculated the p-value.\n",
    "One-Sided Test Adjustment:\n",
    "\n",
    "We discussed how to adjust the code for a one-sided hypothesis test, where youâ€™re only interested in whether the observed proportion of patients with health score improvements is greater than what would be expected by chance.\n",
    "This involved modifying the condition for \"as or more extreme\" simulated statistics to focus only on one direction (greater-than) rather than both directions (greater or lesser).\n",
    "Interpretation of Hypothesis Tests:\n",
    "\n",
    "In a two-tailed test, deviations in both directions (higher or lower than the null hypothesis value) are considered, making the p-value larger since it accounts for both extremes.\n",
    "In a one-tailed test, you only test deviations in one direction (greater than expected), so the p-value is typically smaller because it focuses on a single tail of the distribution.\n",
    "Expected Difference in p-values:\n",
    "\n",
    "For the same observed statistic, the p-value in a one-tailed test is usually smaller than in a two-tailed test because you're considering fewer extreme outcomes (only in one direction).\n",
    "However, this is only true if the observed statistic falls in the direction you're testing (e.g., greater improvement). If not, the one-tailed p-value could be larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b2f551",
   "metadata": {},
   "source": [
    "#### Link: https://chatgpt.com/share/670b064c-de6c-8003-ac55-7d6d43c096ef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04d4dd",
   "metadata": {},
   "source": [
    "## Q8:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729b880",
   "metadata": {},
   "source": [
    "Relationship: This experiment is based on the original experiment but with bigger sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0782e",
   "metadata": {},
   "source": [
    "Null Hypothesis: The probability of people can correctly tell the sequence of putting milk and pouring the tea is 0.5.\n",
    "\n",
    "Alternative hypothesis: The probability of people can correctly tell the sequence of putting milk and pouring the tea is not 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7accace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "H0 = 0.5\n",
    "observed_statistic = 0.6125\n",
    "\n",
    "np.random.seed(1)\n",
    "n = 10000\n",
    "n_size = 80\n",
    "simulation_underH0 = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    random_improvement = np.random.choice([0,1],size = n_size, replace = True)\n",
    "    simulation_underH0[i] = random_improvement.mean()\n",
    "\n",
    "extreme_than_observed = abs(simulation_underH0 - H0) >= abs(observed_statistic - H0)\n",
    "extreme_than_observed.sum()/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c43e8b4",
   "metadata": {},
   "source": [
    "Since 0.01 < p-value = 0.0439 < 0.05, we have moderate evidence against the null hypothesis. Thus, the probability of people can correctly tell the sequence of putting milk and pouring the tea is not 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce076ab",
   "metadata": {},
   "source": [
    "## Q9:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3944330c",
   "metadata": {},
   "source": [
    "Somewhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c5ac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
